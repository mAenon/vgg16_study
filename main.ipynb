{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cofing: utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# データの前処理\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "batch_size = -1 # データの大きさ reshapeしてからshapeの形求める感じでやろう\n",
    "timesteps = 256\n",
    "input_dim = 3 # acc (x, y, z)\n",
    "num_classes = -1 # 分類数\n",
    "\n",
    "x_train, y_train, x_test, y_test = (1, 1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "label_path = home_dir + \"/Desktop/hasc_data/y_large3.csv\"\n",
    "data_path  = home_dir + \"/Desktop/hasc_data/x_large3.csv\"\n",
    "\n",
    "label_df = pd.read_csv(label_path, index_col=0)\n",
    "data_np  = np.loadtxt (data_path , delimiter=\",\").reshape(-1, timesteps, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6 classies validation\n"
    }
   ],
   "source": [
    "# label の取り扱い\n",
    "labels = label_df[\"act\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7 classies validation\n"
    }
   ],
   "source": [
    "# dデータ分割\n",
    "y_train, y_test = sklearn.model_selection.train_test_split(labels, test_size = 0.3, train_size=None, stratify=labels)\n",
    "\n",
    "x_train = data_np[y_train.index]\n",
    "x_test  = data_np[y_test.index]\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "num_classes = len(y_train[0])\n",
    "print(num_classes, \"classies validation\")\n",
    "batch_size = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_18 (InputLayer)        [(None, 256, 3)]          0         \n_________________________________________________________________\nlstm_47 (LSTM)               (None, 256, 256)          266240    \n_________________________________________________________________\nlstm_48 (LSTM)               (None, 256, 256)          525312    \n_________________________________________________________________\nlstm_49 (LSTM)               (None, 256)               525312    \n_________________________________________________________________\ndense_15 (Dense)             (None, 7)                 1799      \n=================================================================\nTotal params: 1,318,663\nTrainable params: 1,318,663\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "input_layer = Input( shape=( timesteps, input_dim ) )\n",
    "lstm1 = LSTM(units=256, activation=\"relu\", kernel_initializer=\"he_normal\", return_sequences=True, dropout=0.1)( input_layer )\n",
    "lstm2 = LSTM(units=256, activation=\"relu\", kernel_initializer=\"he_normal\", return_sequences=True, dropout=0.1)( lstm1 )\n",
    "lstm3 = LSTM(units=256, activation=\"relu\", kernel_initializer=\"he_normal\", dropout=0.1)( lstm2 )\n",
    "dense = Dense(units=num_classes, activation=\"softmax\")( lstm3 )\n",
    "\n",
    "model = Model(inputs = input_layer, outputs = dense)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_to_dotがうまく動かないのでこのセルは実行しないこと\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog=\"dot\", format=\"svg\"))\n",
    "\"\"\"\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=50, verbose=1, callbacks=[EarlyStopping(verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}